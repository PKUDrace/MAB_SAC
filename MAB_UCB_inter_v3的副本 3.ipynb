{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym \n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import pickle\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAB_Smart(gym.Env):\n",
    "    \"\"\"\n",
    "    聪明的 v.s. 单机的\n",
    "    用于训练聪明的策略,具有bouns信息,应对返回6*k+1维状态的多臂老虎机环境\n",
    "    聪明的指：知道赢者通吃规则\n",
    "    \"\"\"\n",
    "    def __init__(self, probs, T,oppo_model):\n",
    "        \"\"\"\n",
    "        初始化多臂老虎机环境\n",
    "        probs: 每个臂的成功概率\n",
    "        T: 总时间步数\n",
    "        \"\"\"\n",
    "        super(MAB_Smart, self).__init__()\n",
    "        self.k = len(probs)  # 臂的数量\n",
    "        self.probs = probs  # 每个臂的成功概率\n",
    "        self.T = T  # 总时间步数\n",
    "        self.oppo_model = oppo_model   # 对手模型\n",
    "\n",
    "        # 定义动作空间和观察空间\n",
    "        self.action_space = spaces.Box(low=1, high=100, shape=(1,), dtype=np.float32)  # 动作空间为alpha\\in[1,100]代指UCB算法中的探索因子\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(6 * self.k + 1,))  # 观察空间为(6*k+1)维向量，每个维度包含三个元素：拉臂的次数、获得的奖励、奖励的方差，对手拉臂的次数、对手获得的奖励、对手的方差以及最后一个元素是时间t\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"\n",
    "        重置环境\n",
    "        返回: 初始状态\n",
    "        \"\"\"\n",
    "        super().reset(seed=seed)\n",
    "        self.steps = 0\n",
    "        self.n = np.zeros(self.k)  # 自己每个臂的拉动次数\n",
    "        self.average_rewards = np.zeros(self.k)  # 自己拉的每个臂奖励的均值\n",
    "        self.rewards = [[] for _ in range(self.k)]  # 自己每个臂的奖励列表\n",
    "        self.var = np.zeros(self.k) # 自己每个臂奖励的方差\n",
    "\n",
    "        self.oppo_n = np.zeros(self.k)  # 对手每个臂的拉动次数\n",
    "        self.oppo_average_rewards = np.zeros(self.k)    # 对手每个臂奖励的均值\n",
    "        self.oppo_rewards = [[] for _ in range(self.k)]    # 对手每个臂的奖励列表\n",
    "        self.oppo_var = np.zeros(self.k)    # 对手每个臂奖励的方差\n",
    "        self.oppo_state = np.zeros(6 * self.k + 1) # 对手的状态,包含两人全部的信息\n",
    "\n",
    "        observation = np.zeros(6 * self.k + 1)  # 初始状态\n",
    "\n",
    "        self.alpha = 1.0  # self初始alpha值\n",
    "        self.oppo_alpha = 1.0  # 对手初始alpha值\n",
    "        info = {}\n",
    "        return observation, info\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        执行给定的动作，并返回结果。\n",
    "        \n",
    "        参数:\n",
    "        action: 智能体选择的alpha值\n",
    "        \n",
    "        返回:\n",
    "        - next_state: 执行动作后的新状态\n",
    "        - reward: 执行动作后获得的奖励\n",
    "        - terminated: 布尔值，表示是否达到终止状态\n",
    "        - truncated: 布尔值，表示是否由于时间限制或其他原因而被截断\n",
    "        - info: 额外的诊断信息（可选）\n",
    "        \"\"\"\n",
    "        self.steps += 1     # 更新步数\n",
    "\n",
    "        # 计算两人开局时面对的汇总信息\n",
    "        total_n = self.n + self.oppo_n  # 总的拉动次数\n",
    "        total_mean = (self.n * self.average_rewards + self.oppo_n * self.oppo_average_rewards) / (total_n + 1e-10)  # 总的奖励均值\n",
    "\n",
    "        # 自己行动\n",
    "        self.alpha = action[0]  # 更新alpha值\n",
    "        self_ucb_values = total_mean + np.sqrt(self.alpha * np.log(2 * self.steps + 1) / (2 * (total_n + 1e-10)))  # 根据汇总信息,计算自己UCB值\n",
    "        self_chosen_arm = np.argmax(self_ucb_values)  # 选择具有最高UCB值的臂\n",
    "\n",
    "        # 自己该次行动的影响: 更新前3*k维的状态\n",
    "        reward = np.random.binomial(1, self.probs[self_chosen_arm])  # 根据奖励概率生成奖励\n",
    "        self.n[self_chosen_arm] += 1\n",
    "        self.rewards[self_chosen_arm].append(reward)  # 更新奖励列表\n",
    "        self.average_rewards[self_chosen_arm] = np.mean(self.rewards[self_chosen_arm])  # 更新奖励均值\n",
    "        self.var[self_chosen_arm] = np.var(self.rewards[self_chosen_arm])#更新奖励方差\n",
    "\n",
    "        # 对手行动:根据上局结束时的状态进行predict，采用上一个时刻面对的全部的信息来选择臂\n",
    "        oppo_state_tensor = th.tensor(self.oppo_state, dtype=th.float32).unsqueeze(0) # 将上局结束时的状态转换为张量\n",
    "        oppo_action, _ = self.oppo_model.predict(oppo_state_tensor, deterministic=True)  # 根据上局结束的状态，对手给出预测的alpha值\n",
    "        self.oppo_alpha = oppo_action[0] # 对手的alpha值\n",
    "        oppo_ucb_values = total_mean + np.sqrt(self.oppo_alpha * np.log(2*self.steps + 1) / (2 * (total_n + 1e-10))) # 根据汇总信息,计算对手UCB值\n",
    "        oppo_chosen_arm = np.argmax(oppo_ucb_values) # 对手选择具有最高UCB值的臂\n",
    "\n",
    "        # 对手该次行动的影响: 只影响对手\n",
    "        oppo_reward = np.random.binomial(1, self.probs[oppo_chosen_arm]) # 根据奖励概率生成奖励\n",
    "        self.oppo_n[oppo_chosen_arm] += 1 # 更新对手的拉动次数\n",
    "        self.oppo_rewards[oppo_chosen_arm].append(oppo_reward) # 更新对手的奖励列表\n",
    "        self.oppo_average_rewards[oppo_chosen_arm] = np.mean(self.oppo_rewards[oppo_chosen_arm])    # 更新对手的奖励均值\n",
    "        self.oppo_var[oppo_chosen_arm] = np.var(self.oppo_rewards[oppo_chosen_arm])     # 更新对手的奖励方差\n",
    "\n",
    "\n",
    "        #   更新对手的状态，前3*k维为对手的信息，后3*k维为self的信息\n",
    "        self.oppo_state = np.concatenate([self.oppo_n, self.oppo_average_rewards, self.oppo_var, self.n, self.average_rewards, self.var, [self.steps]]) # 更新对手的状态,包含两人全部的信息\n",
    "\n",
    "\n",
    "        \n",
    "        terminated = self.steps >= self.T  # 判断是否达到最大步数\n",
    "        truncated = self.steps >= self.T  # 在这个示例中，截断条件与终止条件相同\n",
    "        next_state = np.concatenate([self.n, self.average_rewards, self.var, self.oppo_n, self.oppo_average_rewards, self.oppo_var, [self.steps]])  # 更新自身状态,包含两人全部的信息\n",
    "        info = {} # 可选的额外信息\n",
    "        if terminated:\n",
    "            self_total_rewards = sum(sum(rewards) for rewards in self.rewards)\n",
    "            oppo_total_rewards = sum(sum(rewards) for rewards in self.oppo_rewards)\n",
    "            if self_total_rewards > oppo_total_rewards:\n",
    "                reward += oppo_total_rewards\n",
    "            elif self_total_rewards < oppo_total_rewards:\n",
    "                reward += -self_total_rewards\n",
    "\n",
    "        return next_state, reward, terminated, truncated, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward_episode(model_name, env, T, n_episodes,is_print=False,is_reward=True):\n",
    "    \"\"\"\n",
    "    is_reward: 是否需要重结算对手的收益\n",
    "    用训练出的策略模型,在确定和随机的条件下,与分别环境进行n_episodes交互,分别计算各步累计收益的平均值,并绘制平均收益和平均的alpha随时间步的变化\n",
    "    \"\"\"\n",
    "    # 初始化确定策略和随机策略的各步的平均累计收益(n_episdodes次交互的总和)\n",
    "    self_rewards_sum = np.zeros(T)\n",
    "    # 初始化确定策略和随机策略的各步的平均alpha\n",
    "    self_alphas_sum = np.zeros(T)\n",
    "    # 初始化对手的各步的平均累计收益(n_episdodes次交互的总和)\n",
    "    oppo_rewards_sum = np.zeros(T)\n",
    "    # 初始化对手的各步的alpha的总和\n",
    "    oppo_alphas_sum = np.zeros(T)\n",
    "\n",
    "    for episode_index in range(n_episodes):\n",
    "        # 初始化确定策略每步自身和对手的累计收益\n",
    "        self_reward_episode = np.zeros(T)\n",
    "        oppo_reward_epsisode = np.zeros(T)\n",
    "        # 重置环境，获取初始状态\n",
    "        state, _ = env.reset()\n",
    "        # 确定策略与环境进行交互\n",
    "        for t in range(T):\n",
    "            # 将状态转换为 PyTorch 张量，并添加批量维度\n",
    "            state_tensor = th.tensor(state, dtype=th.float32).unsqueeze(0)\n",
    "            # 交互\n",
    "            action, _ = model_name.predict(state_tensor, deterministic=True)\n",
    "            next_state, reward, terminated, truncated, info = env.step(action)\n",
    "            # 更新确定策略的累计对手收益\n",
    "            oppo_reward_epsisode[t] = sum(state[3*env.k:4*env.k]*state[4*env.k:5*env.k])\n",
    "            # 更新确定策略的累计自身收益\n",
    "            if t == 0:\n",
    "                self_reward_episode[t] = reward\n",
    "            else:\n",
    "                self_reward_episode[t] = reward+self_reward_episode[t-1]\n",
    "            \n",
    "            # 更新确定策略的累计alpha\n",
    "            self_alphas_sum[t] += action\n",
    "            oppo_alphas_sum[t] += env.oppo_alpha\n",
    "\n",
    "            # 与环境交互\n",
    "            state = next_state\n",
    "        # 加上确定策略的本次交互的累计收益\n",
    "        self_rewards_sum += self_reward_episode\n",
    "        oppo_rewards_sum += oppo_reward_epsisode\n",
    "        if is_reward:\n",
    "            # 根据最终状态中对手和自己的累计受益再次结算收益\n",
    "            self_arms_n = state[:env.k]\n",
    "            self_arms_rewards_mean = state[env.k:2*env.k]\n",
    "            oppo_arm_n = state[3*env.k:4*env.k]\n",
    "            oppo_arm_rewards_mean = state[4*env.k:5*env.k]\n",
    "            self_total_rewards = sum(self_arms_n[i]*self_arms_rewards_mean[i] for i in range(env.k))\n",
    "            oppo_total_rewards = sum(oppo_arm_n[i]*oppo_arm_rewards_mean[i] for i in range(env.k))\n",
    "            if self_total_rewards > oppo_total_rewards:\n",
    "                oppo_rewards_sum[T-1] += -oppo_total_rewards\n",
    "            elif self_total_rewards < oppo_total_rewards:\n",
    "                oppo_rewards_sum[T-1] += self_total_rewards\n",
    "        if is_print:\n",
    "            print('Episode:', episode_index + 1)\n",
    "\n",
    "        \n",
    "    # 计算episode内两人每步的平均累计收益\n",
    "    self_rewards_mean = self_rewards_sum / n_episodes\n",
    "    oppo_rewards_mean = oppo_rewards_sum / n_episodes\n",
    "    # 计算episode内两人每步的平均alpha\n",
    "    self_alphas_mean = self_alphas_sum / n_episodes\n",
    "    oppo_alphas_mean = oppo_alphas_sum / n_episodes\n",
    "    return self_rewards_mean, self_alphas_mean, oppo_rewards_mean, oppo_alphas_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行多轮训练\n",
    "\n",
    "按一定轮次的频率保存训练所得的策略\n",
    "\n",
    "后续读取训练结果，绘出平均最终收益随训练轮次的变化情况\n",
    "\n",
    "\n",
    "重点关注参数：\n",
    "参数名      | 描述 |\n",
    "| ----------- | ----------- |\n",
    "| probs      | 多臂老虎机设定       |\n",
    "| T      | 每轮拉臂的次数       |\n",
    "| total_timesteps      | 总训练轮数       |\n",
    "| check_freq      | 训练结果保存频率       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "伯努利多臂老虎机的概率为： ['0.4170', '0.7203', '0.0001', '0.3023', '0.1468']\n"
     ]
    }
   ],
   "source": [
    "# 多臂老虎机的基本设定\n",
    "np.random.seed(1)\n",
    "probs = np.random.rand(5)\n",
    "formatted_probs = [f\"{prob:.4f}\" for prob in probs]\n",
    "print(\"伯努利多臂老虎机的概率为：\", formatted_probs)\n",
    "T = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 17.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 275      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 200      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.47    |\n",
      "|    critic_loss     | 1.66     |\n",
      "|    ent_coef        | 0.971    |\n",
      "|    ent_coef_loss   | -0.0492  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 99       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 22.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 211      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 400      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.24    |\n",
      "|    critic_loss     | 1.99     |\n",
      "|    ent_coef        | 0.914    |\n",
      "|    ent_coef_loss   | -0.15    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 299      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 21.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 191      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 600      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.63    |\n",
      "|    critic_loss     | 3.1      |\n",
      "|    ent_coef        | 0.861    |\n",
      "|    ent_coef_loss   | -0.248   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 499      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 22       |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 800      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.41    |\n",
      "|    critic_loss     | 1.84     |\n",
      "|    ent_coef        | 0.811    |\n",
      "|    ent_coef_loss   | -0.353   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 699      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 23.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 181      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 1000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.75    |\n",
      "|    critic_loss     | 1.44     |\n",
      "|    ent_coef        | 0.764    |\n",
      "|    ent_coef_loss   | -0.437   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 899      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 22.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 181      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 1200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.54    |\n",
      "|    critic_loss     | 7.23     |\n",
      "|    ent_coef        | 0.72     |\n",
      "|    ent_coef_loss   | -0.548   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 25.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 177      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 1400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.62    |\n",
      "|    critic_loss     | 3.91     |\n",
      "|    ent_coef        | 0.679    |\n",
      "|    ent_coef_loss   | -0.637   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 27       |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 172      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 1600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.66    |\n",
      "|    critic_loss     | 3.66     |\n",
      "|    ent_coef        | 0.64     |\n",
      "|    ent_coef_loss   | -0.726   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 27.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 171      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 1800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.79    |\n",
      "|    critic_loss     | 1.79     |\n",
      "|    ent_coef        | 0.603    |\n",
      "|    ent_coef_loss   | -0.816   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1699     |\n",
      "---------------------------------\n",
      "Saving model checkpoint to model_2000.zip\n",
      "Model model_2000.zip has been saved.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 27       |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 2000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.12    |\n",
      "|    critic_loss     | 1.55     |\n",
      "|    ent_coef        | 0.569    |\n",
      "|    ent_coef_loss   | -0.93    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 2200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.82    |\n",
      "|    critic_loss     | 1.39     |\n",
      "|    ent_coef        | 0.537    |\n",
      "|    ent_coef_loss   | -1.02    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 171      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 2400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.41    |\n",
      "|    critic_loss     | 3.7      |\n",
      "|    ent_coef        | 0.506    |\n",
      "|    ent_coef_loss   | -1.09    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 27.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 2600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.67    |\n",
      "|    critic_loss     | 2.57     |\n",
      "|    ent_coef        | 0.477    |\n",
      "|    ent_coef_loss   | -1.15    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 2800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.09    |\n",
      "|    critic_loss     | 4.87     |\n",
      "|    ent_coef        | 0.45     |\n",
      "|    ent_coef_loss   | -1.26    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 27.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 166      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 3000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.99    |\n",
      "|    critic_loss     | 1.81     |\n",
      "|    ent_coef        | 0.424    |\n",
      "|    ent_coef_loss   | -1.39    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 27       |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 167      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 3200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10      |\n",
      "|    critic_loss     | 2.38     |\n",
      "|    ent_coef        | 0.4      |\n",
      "|    ent_coef_loss   | -1.33    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 167      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 3400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.4    |\n",
      "|    critic_loss     | 0.955    |\n",
      "|    ent_coef        | 0.378    |\n",
      "|    ent_coef_loss   | -1.47    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 3600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.6    |\n",
      "|    critic_loss     | 5.24     |\n",
      "|    ent_coef        | 0.356    |\n",
      "|    ent_coef_loss   | -1.54    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 3800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.2    |\n",
      "|    critic_loss     | 1.45     |\n",
      "|    ent_coef        | 0.336    |\n",
      "|    ent_coef_loss   | -1.69    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3699     |\n",
      "---------------------------------\n",
      "Saving model checkpoint to model_4000.zip\n",
      "Model model_4000.zip has been saved.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11      |\n",
      "|    critic_loss     | 1.9      |\n",
      "|    ent_coef        | 0.317    |\n",
      "|    ent_coef_loss   | -1.69    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 4200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.9    |\n",
      "|    critic_loss     | 2.54     |\n",
      "|    ent_coef        | 0.299    |\n",
      "|    ent_coef_loss   | -1.86    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 171      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 4400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.8    |\n",
      "|    critic_loss     | 9.98     |\n",
      "|    ent_coef        | 0.282    |\n",
      "|    ent_coef_loss   | -1.75    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 25.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 171      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 4600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.7    |\n",
      "|    critic_loss     | 2.8      |\n",
      "|    ent_coef        | 0.266    |\n",
      "|    ent_coef_loss   | -1.85    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 25.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 172      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 4800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.6    |\n",
      "|    critic_loss     | 1.93     |\n",
      "|    ent_coef        | 0.252    |\n",
      "|    ent_coef_loss   | -2.03    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 25.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 172      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 5000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.5    |\n",
      "|    critic_loss     | 1.84     |\n",
      "|    ent_coef        | 0.238    |\n",
      "|    ent_coef_loss   | -2.01    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 172      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 5200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.8    |\n",
      "|    critic_loss     | 2.83     |\n",
      "|    ent_coef        | 0.224    |\n",
      "|    ent_coef_loss   | -2.19    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 173      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 5400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.5    |\n",
      "|    critic_loss     | 2.35     |\n",
      "|    ent_coef        | 0.212    |\n",
      "|    ent_coef_loss   | -2.07    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 173      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 5600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.6    |\n",
      "|    critic_loss     | 3.07     |\n",
      "|    ent_coef        | 0.2      |\n",
      "|    ent_coef_loss   | -2.1     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 174      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 5800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.1    |\n",
      "|    critic_loss     | 4.71     |\n",
      "|    ent_coef        | 0.189    |\n",
      "|    ent_coef_loss   | -2.21    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5699     |\n",
      "---------------------------------\n",
      "Saving model checkpoint to model_6000.zip\n",
      "Model model_6000.zip has been saved.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 174      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 6000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.8    |\n",
      "|    critic_loss     | 1.92     |\n",
      "|    ent_coef        | 0.179    |\n",
      "|    ent_coef_loss   | -2.11    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 174      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 6200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14      |\n",
      "|    critic_loss     | 3.49     |\n",
      "|    ent_coef        | 0.169    |\n",
      "|    ent_coef_loss   | -2.38    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 175      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 6400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.3    |\n",
      "|    critic_loss     | 1.4      |\n",
      "|    ent_coef        | 0.16     |\n",
      "|    ent_coef_loss   | -2.48    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 25.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 175      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 6600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.8    |\n",
      "|    critic_loss     | 2.94     |\n",
      "|    ent_coef        | 0.152    |\n",
      "|    ent_coef_loss   | -2.56    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 25.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 175      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 6800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.2    |\n",
      "|    critic_loss     | 2.3      |\n",
      "|    ent_coef        | 0.143    |\n",
      "|    ent_coef_loss   | -2.54    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 176      |\n",
      "|    time_elapsed    | 39       |\n",
      "|    total_timesteps | 7000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.4    |\n",
      "|    critic_loss     | 2.23     |\n",
      "|    ent_coef        | 0.136    |\n",
      "|    ent_coef_loss   | -2.32    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 176      |\n",
      "|    time_elapsed    | 40       |\n",
      "|    total_timesteps | 7200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15      |\n",
      "|    critic_loss     | 4.12     |\n",
      "|    ent_coef        | 0.129    |\n",
      "|    ent_coef_loss   | -2.51    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 176      |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 7400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.1    |\n",
      "|    critic_loss     | 4.59     |\n",
      "|    ent_coef        | 0.122    |\n",
      "|    ent_coef_loss   | -2.42    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 176      |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 7600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15      |\n",
      "|    critic_loss     | 2.67     |\n",
      "|    ent_coef        | 0.115    |\n",
      "|    ent_coef_loss   | -2.57    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 27.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 177      |\n",
      "|    time_elapsed    | 44       |\n",
      "|    total_timesteps | 7800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.1    |\n",
      "|    critic_loss     | 2.01     |\n",
      "|    ent_coef        | 0.109    |\n",
      "|    ent_coef_loss   | -2.32    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7699     |\n",
      "---------------------------------\n",
      "Saving model checkpoint to model_8000.zip\n",
      "Model model_8000.zip has been saved.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 26.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 176      |\n",
      "|    time_elapsed    | 45       |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.5    |\n",
      "|    critic_loss     | 4.4      |\n",
      "|    ent_coef        | 0.103    |\n",
      "|    ent_coef_loss   | -2.45    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 27.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 176      |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 8200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.6    |\n",
      "|    critic_loss     | 1.67     |\n",
      "|    ent_coef        | 0.0978   |\n",
      "|    ent_coef_loss   | -2.37    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 28.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 176      |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total_timesteps | 8400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.2    |\n",
      "|    critic_loss     | 3.06     |\n",
      "|    ent_coef        | 0.0928   |\n",
      "|    ent_coef_loss   | -2.46    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 28.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 176      |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 8600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.7    |\n",
      "|    critic_loss     | 2.87     |\n",
      "|    ent_coef        | 0.0881   |\n",
      "|    ent_coef_loss   | -2.2     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 28.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 176      |\n",
      "|    time_elapsed    | 49       |\n",
      "|    total_timesteps | 8800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.2    |\n",
      "|    critic_loss     | 1.93     |\n",
      "|    ent_coef        | 0.0836   |\n",
      "|    ent_coef_loss   | -2.48    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 28.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 177      |\n",
      "|    time_elapsed    | 50       |\n",
      "|    total_timesteps | 9000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.8    |\n",
      "|    critic_loss     | 2.48     |\n",
      "|    ent_coef        | 0.0794   |\n",
      "|    ent_coef_loss   | -2.36    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 29.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 177      |\n",
      "|    time_elapsed    | 51       |\n",
      "|    total_timesteps | 9200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.6    |\n",
      "|    critic_loss     | 3.09     |\n",
      "|    ent_coef        | 0.0756   |\n",
      "|    ent_coef_loss   | -2.33    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 28.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 177      |\n",
      "|    time_elapsed    | 53       |\n",
      "|    total_timesteps | 9400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.9    |\n",
      "|    critic_loss     | 3.17     |\n",
      "|    ent_coef        | 0.072    |\n",
      "|    ent_coef_loss   | -2.13    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 29.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 177      |\n",
      "|    time_elapsed    | 54       |\n",
      "|    total_timesteps | 9600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.9    |\n",
      "|    critic_loss     | 2.89     |\n",
      "|    ent_coef        | 0.0687   |\n",
      "|    ent_coef_loss   | -2.17    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 29.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 177      |\n",
      "|    time_elapsed    | 55       |\n",
      "|    total_timesteps | 9800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.8    |\n",
      "|    critic_loss     | 2.5      |\n",
      "|    ent_coef        | 0.0654   |\n",
      "|    ent_coef_loss   | -2.06    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9699     |\n",
      "---------------------------------\n",
      "Saving model checkpoint to model_10000.zip\n",
      "Model model_10000.zip has been saved.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 29.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 177      |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.5    |\n",
      "|    critic_loss     | 3.48     |\n",
      "|    ent_coef        | 0.0623   |\n",
      "|    ent_coef_loss   | -1.77    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 29.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 177      |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 10200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.6    |\n",
      "|    critic_loss     | 2.39     |\n",
      "|    ent_coef        | 0.0595   |\n",
      "|    ent_coef_loss   | -2.22    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 10099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 30.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 178      |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 10400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.5    |\n",
      "|    critic_loss     | 4.2      |\n",
      "|    ent_coef        | 0.0568   |\n",
      "|    ent_coef_loss   | -2.28    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 10299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 30.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 178      |\n",
      "|    time_elapsed    | 59       |\n",
      "|    total_timesteps | 10600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.3    |\n",
      "|    critic_loss     | 2.71     |\n",
      "|    ent_coef        | 0.0542   |\n",
      "|    ent_coef_loss   | -1.35    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 10499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 30.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 178      |\n",
      "|    time_elapsed    | 60       |\n",
      "|    total_timesteps | 10800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.7    |\n",
      "|    critic_loss     | 2.05     |\n",
      "|    ent_coef        | 0.0517   |\n",
      "|    ent_coef_loss   | -2.08    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 10699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 178      |\n",
      "|    time_elapsed    | 61       |\n",
      "|    total_timesteps | 11000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.6    |\n",
      "|    critic_loss     | 2.41     |\n",
      "|    ent_coef        | 0.0493   |\n",
      "|    ent_coef_loss   | -2.27    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 10899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 178      |\n",
      "|    time_elapsed    | 62       |\n",
      "|    total_timesteps | 11200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.9    |\n",
      "|    critic_loss     | 2.26     |\n",
      "|    ent_coef        | 0.0471   |\n",
      "|    ent_coef_loss   | -1.93    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 11099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 178      |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 11400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.2    |\n",
      "|    critic_loss     | 3.95     |\n",
      "|    ent_coef        | 0.0451   |\n",
      "|    ent_coef_loss   | -1.47    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 11299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 178      |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 11600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.3    |\n",
      "|    critic_loss     | 3.57     |\n",
      "|    ent_coef        | 0.0433   |\n",
      "|    ent_coef_loss   | -0.683   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 11499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 178      |\n",
      "|    time_elapsed    | 65       |\n",
      "|    total_timesteps | 11800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16      |\n",
      "|    critic_loss     | 3.14     |\n",
      "|    ent_coef        | 0.0416   |\n",
      "|    ent_coef_loss   | -1.31    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 11699    |\n",
      "---------------------------------\n",
      "Saving model checkpoint to model_12000.zip\n",
      "Model model_12000.zip has been saved.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 179      |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 12000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.8    |\n",
      "|    critic_loss     | 3.88     |\n",
      "|    ent_coef        | 0.04     |\n",
      "|    ent_coef_loss   | -1.13    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 11899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 179      |\n",
      "|    time_elapsed    | 68       |\n",
      "|    total_timesteps | 12200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.6    |\n",
      "|    critic_loss     | 6.49     |\n",
      "|    ent_coef        | 0.0385   |\n",
      "|    ent_coef_loss   | -0.839   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 12099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 179      |\n",
      "|    time_elapsed    | 69       |\n",
      "|    total_timesteps | 12400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.5    |\n",
      "|    critic_loss     | 2.27     |\n",
      "|    ent_coef        | 0.0372   |\n",
      "|    ent_coef_loss   | -1.06    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 12299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 179      |\n",
      "|    time_elapsed    | 70       |\n",
      "|    total_timesteps | 12600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.7    |\n",
      "|    critic_loss     | 2.9      |\n",
      "|    ent_coef        | 0.0358   |\n",
      "|    ent_coef_loss   | -1.73    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 12499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 179      |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 12800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.2    |\n",
      "|    critic_loss     | 2.65     |\n",
      "|    ent_coef        | 0.0346   |\n",
      "|    ent_coef_loss   | -0.355   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 12699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 179      |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 13000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.4    |\n",
      "|    critic_loss     | 3.43     |\n",
      "|    ent_coef        | 0.0334   |\n",
      "|    ent_coef_loss   | -0.995   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 12899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 179      |\n",
      "|    time_elapsed    | 73       |\n",
      "|    total_timesteps | 13200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.2    |\n",
      "|    critic_loss     | 3.02     |\n",
      "|    ent_coef        | 0.0325   |\n",
      "|    ent_coef_loss   | -0.291   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 13099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 179      |\n",
      "|    time_elapsed    | 74       |\n",
      "|    total_timesteps | 13400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.3    |\n",
      "|    critic_loss     | 2.97     |\n",
      "|    ent_coef        | 0.0315   |\n",
      "|    ent_coef_loss   | -1.06    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 13299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 179      |\n",
      "|    time_elapsed    | 75       |\n",
      "|    total_timesteps | 13600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.7    |\n",
      "|    critic_loss     | 2.91     |\n",
      "|    ent_coef        | 0.0308   |\n",
      "|    ent_coef_loss   | 0.124    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 13499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 179      |\n",
      "|    time_elapsed    | 76       |\n",
      "|    total_timesteps | 13800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.3    |\n",
      "|    critic_loss     | 2.54     |\n",
      "|    ent_coef        | 0.0301   |\n",
      "|    ent_coef_loss   | -0.364   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 13699    |\n",
      "---------------------------------\n",
      "Saving model checkpoint to model_14000.zip\n",
      "Model model_14000.zip has been saved.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 179      |\n",
      "|    time_elapsed    | 77       |\n",
      "|    total_timesteps | 14000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.8    |\n",
      "|    critic_loss     | 4.45     |\n",
      "|    ent_coef        | 0.0294   |\n",
      "|    ent_coef_loss   | 1.01     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 13899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 179      |\n",
      "|    time_elapsed    | 78       |\n",
      "|    total_timesteps | 14200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.6    |\n",
      "|    critic_loss     | 2.33     |\n",
      "|    ent_coef        | 0.0289   |\n",
      "|    ent_coef_loss   | -0.401   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 32.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 79       |\n",
      "|    total_timesteps | 14400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17      |\n",
      "|    critic_loss     | 3.26     |\n",
      "|    ent_coef        | 0.0284   |\n",
      "|    ent_coef_loss   | -0.615   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 32.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 292      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 81       |\n",
      "|    total_timesteps | 14600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.8    |\n",
      "|    critic_loss     | 2.94     |\n",
      "|    ent_coef        | 0.0283   |\n",
      "|    ent_coef_loss   | 0.0609   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 32.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 82       |\n",
      "|    total_timesteps | 14800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.4    |\n",
      "|    critic_loss     | 2.53     |\n",
      "|    ent_coef        | 0.028    |\n",
      "|    ent_coef_loss   | -0.509   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 32       |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 83       |\n",
      "|    total_timesteps | 15000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.9    |\n",
      "|    critic_loss     | 3.02     |\n",
      "|    ent_coef        | 0.0282   |\n",
      "|    ent_coef_loss   | 0.0954   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 32.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 304      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 84       |\n",
      "|    total_timesteps | 15200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.2    |\n",
      "|    critic_loss     | 4.24     |\n",
      "|    ent_coef        | 0.0282   |\n",
      "|    ent_coef_loss   | -0.156   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 15099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 308      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 85       |\n",
      "|    total_timesteps | 15400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.1    |\n",
      "|    critic_loss     | 2.69     |\n",
      "|    ent_coef        | 0.0277   |\n",
      "|    ent_coef_loss   | 0.291    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 15299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 312      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 86       |\n",
      "|    total_timesteps | 15600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.9    |\n",
      "|    critic_loss     | 3.99     |\n",
      "|    ent_coef        | 0.0279   |\n",
      "|    ent_coef_loss   | 0.951    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 15499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 316      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 87       |\n",
      "|    total_timesteps | 15800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.3    |\n",
      "|    critic_loss     | 4.9      |\n",
      "|    ent_coef        | 0.028    |\n",
      "|    ent_coef_loss   | 0.403    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 15699    |\n",
      "---------------------------------\n",
      "Saving model checkpoint to model_16000.zip\n",
      "Model model_16000.zip has been saved.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 320      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 88       |\n",
      "|    total_timesteps | 16000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.2    |\n",
      "|    critic_loss     | 3.51     |\n",
      "|    ent_coef        | 0.028    |\n",
      "|    ent_coef_loss   | -0.561   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 15899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 324      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 89       |\n",
      "|    total_timesteps | 16200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.9    |\n",
      "|    critic_loss     | 3.25     |\n",
      "|    ent_coef        | 0.0278   |\n",
      "|    ent_coef_loss   | -0.265   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 16099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 328      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 90       |\n",
      "|    total_timesteps | 16400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.2    |\n",
      "|    critic_loss     | 2.62     |\n",
      "|    ent_coef        | 0.0279   |\n",
      "|    ent_coef_loss   | -0.883   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 16299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 332      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 91       |\n",
      "|    total_timesteps | 16600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.5    |\n",
      "|    critic_loss     | 3.02     |\n",
      "|    ent_coef        | 0.0283   |\n",
      "|    ent_coef_loss   | 1.07     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 16499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 32.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 336      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 92       |\n",
      "|    total_timesteps | 16800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16      |\n",
      "|    critic_loss     | 4        |\n",
      "|    ent_coef        | 0.0286   |\n",
      "|    ent_coef_loss   | 0.00265  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 16699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 32.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 340      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 93       |\n",
      "|    total_timesteps | 17000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.6    |\n",
      "|    critic_loss     | 3.09     |\n",
      "|    ent_coef        | 0.029    |\n",
      "|    ent_coef_loss   | -0.52    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 16899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 32.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 344      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 95       |\n",
      "|    total_timesteps | 17200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.6    |\n",
      "|    critic_loss     | 2.76     |\n",
      "|    ent_coef        | 0.0292   |\n",
      "|    ent_coef_loss   | 1.39     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 17099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 32.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 348      |\n",
      "|    fps             | 181      |\n",
      "|    time_elapsed    | 96       |\n",
      "|    total_timesteps | 17400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.5    |\n",
      "|    critic_loss     | 2.58     |\n",
      "|    ent_coef        | 0.0294   |\n",
      "|    ent_coef_loss   | 0.0313   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 17299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 32.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 352      |\n",
      "|    fps             | 181      |\n",
      "|    time_elapsed    | 97       |\n",
      "|    total_timesteps | 17600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.7    |\n",
      "|    critic_loss     | 3.46     |\n",
      "|    ent_coef        | 0.0294   |\n",
      "|    ent_coef_loss   | 1.6      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 17499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 356      |\n",
      "|    fps             | 181      |\n",
      "|    time_elapsed    | 98       |\n",
      "|    total_timesteps | 17800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.3    |\n",
      "|    critic_loss     | 3.31     |\n",
      "|    ent_coef        | 0.03     |\n",
      "|    ent_coef_loss   | -0.526   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 17699    |\n",
      "---------------------------------\n",
      "Saving model checkpoint to model_18000.zip\n",
      "Model model_18000.zip has been saved.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 360      |\n",
      "|    fps             | 181      |\n",
      "|    time_elapsed    | 99       |\n",
      "|    total_timesteps | 18000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.3    |\n",
      "|    critic_loss     | 2.65     |\n",
      "|    ent_coef        | 0.0299   |\n",
      "|    ent_coef_loss   | 0.00607  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 17899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 364      |\n",
      "|    fps             | 181      |\n",
      "|    time_elapsed    | 100      |\n",
      "|    total_timesteps | 18200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.9    |\n",
      "|    critic_loss     | 3.01     |\n",
      "|    ent_coef        | 0.0299   |\n",
      "|    ent_coef_loss   | -0.138   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 18099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 368      |\n",
      "|    fps             | 181      |\n",
      "|    time_elapsed    | 101      |\n",
      "|    total_timesteps | 18400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.2    |\n",
      "|    critic_loss     | 2.9      |\n",
      "|    ent_coef        | 0.0304   |\n",
      "|    ent_coef_loss   | 1.26     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 18299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 372      |\n",
      "|    fps             | 181      |\n",
      "|    time_elapsed    | 102      |\n",
      "|    total_timesteps | 18600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.5    |\n",
      "|    critic_loss     | 3.59     |\n",
      "|    ent_coef        | 0.0301   |\n",
      "|    ent_coef_loss   | 0.698    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 18499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 376      |\n",
      "|    fps             | 181      |\n",
      "|    time_elapsed    | 103      |\n",
      "|    total_timesteps | 18800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18      |\n",
      "|    critic_loss     | 3.17     |\n",
      "|    ent_coef        | 0.0302   |\n",
      "|    ent_coef_loss   | 0.384    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 18699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 380      |\n",
      "|    fps             | 181      |\n",
      "|    time_elapsed    | 104      |\n",
      "|    total_timesteps | 19000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.6    |\n",
      "|    critic_loss     | 2.45     |\n",
      "|    ent_coef        | 0.0301   |\n",
      "|    ent_coef_loss   | -0.516   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 18899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 384      |\n",
      "|    fps             | 181      |\n",
      "|    time_elapsed    | 105      |\n",
      "|    total_timesteps | 19200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.2    |\n",
      "|    critic_loss     | 3.2      |\n",
      "|    ent_coef        | 0.0299   |\n",
      "|    ent_coef_loss   | -0.868   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 388      |\n",
      "|    fps             | 181      |\n",
      "|    time_elapsed    | 107      |\n",
      "|    total_timesteps | 19400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.2    |\n",
      "|    critic_loss     | 2.86     |\n",
      "|    ent_coef        | 0.0302   |\n",
      "|    ent_coef_loss   | 0.0267   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 392      |\n",
      "|    fps             | 181      |\n",
      "|    time_elapsed    | 108      |\n",
      "|    total_timesteps | 19600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.5    |\n",
      "|    critic_loss     | 3.09     |\n",
      "|    ent_coef        | 0.0304   |\n",
      "|    ent_coef_loss   | -0.615   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 32.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 396      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 109      |\n",
      "|    total_timesteps | 19800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.1    |\n",
      "|    critic_loss     | 2.29     |\n",
      "|    ent_coef        | 0.0305   |\n",
      "|    ent_coef_loss   | -0.239   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19699    |\n",
      "---------------------------------\n",
      "Saving model checkpoint to model_20000.zip\n",
      "Model model_20000.zip has been saved.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 110      |\n",
      "|    total_timesteps | 20000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.7    |\n",
      "|    critic_loss     | 2.96     |\n",
      "|    ent_coef        | 0.0308   |\n",
      "|    ent_coef_loss   | -0.923   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 32.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 404      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 20200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.1    |\n",
      "|    critic_loss     | 4.96     |\n",
      "|    ent_coef        | 0.0306   |\n",
      "|    ent_coef_loss   | 0.0234   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 20099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 408      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 20400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17      |\n",
      "|    critic_loss     | 3.06     |\n",
      "|    ent_coef        | 0.0306   |\n",
      "|    ent_coef_loss   | -0.517   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 20299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 412      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 20600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.2    |\n",
      "|    critic_loss     | 2.99     |\n",
      "|    ent_coef        | 0.0309   |\n",
      "|    ent_coef_loss   | -0.407   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 20499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 32.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 416      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 115      |\n",
      "|    total_timesteps | 20800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.8    |\n",
      "|    critic_loss     | 6.82     |\n",
      "|    ent_coef        | 0.0312   |\n",
      "|    ent_coef_loss   | -0.852   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 20699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 32       |\n",
      "| time/              |          |\n",
      "|    episodes        | 420      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 116      |\n",
      "|    total_timesteps | 21000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.9    |\n",
      "|    critic_loss     | 2.48     |\n",
      "|    ent_coef        | 0.0309   |\n",
      "|    ent_coef_loss   | -1.05    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 20899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 424      |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 117      |\n",
      "|    total_timesteps | 21200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.1    |\n",
      "|    critic_loss     | 2.39     |\n",
      "|    ent_coef        | 0.0305   |\n",
      "|    ent_coef_loss   | 0.382    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 21099    |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 训练smart_policy_v3\n",
    "oppo_model = SAC.load(\"smart_UCB_v0\")\n",
    "smart_env_v3 = MAB_Smart(probs,T,oppo_model)\n",
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    def __init__(self, check_freq: int, save_path: str, verbose: int = 1):\n",
    "        super(SaveOnBestTrainingRewardCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_filename = f'model_{self.n_calls}.zip'\n",
    "            model_path = os.path.join(self.save_path, model_filename)\n",
    "            self.model.save(model_path)\n",
    "            if self.verbose > 0:\n",
    "                print(f\"Saving model checkpoint to {model_filename}\")\n",
    "                print(f\"Model {model_filename} has been saved.\")\n",
    "        return True\n",
    "    \n",
    "# 定义保存路径和检查频率\n",
    "save_path1 = '/Users/fengyilong/Git/MAB_SAC/UCB_smart_v3'\n",
    "check_freq = 2000\n",
    "\n",
    "# 创建回调函数实例\n",
    "callback1 = SaveOnBestTrainingRewardCallback(check_freq=check_freq, save_path=save_path1)\n",
    "# 创建模型\n",
    "smart_model_v3 = SAC(\"MlpPolicy\", smart_env_v3, gamma=1, verbose=2)\n",
    "\n",
    "total_timesteps = 100000\n",
    "\n",
    "# 训练模型并使用回调函数\n",
    "smart_model_v3.learn(total_timesteps, callback=callback1)\n",
    "\n",
    "smart_model_v3.save(\"smart_UCB_v3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算平均累计收益\n",
    "self_rewards_v3 = []\n",
    "oppo_rewards_v3 = []\n",
    "timesteps = []\n",
    "n_episodes = 10000\n",
    "\n",
    "# 处理策略\n",
    "for step in range(check_freq, total_timesteps + 1, check_freq):\n",
    "    print(\"解压:\", step)\n",
    "    model_filename = f'model_{step}.zip'\n",
    "    model_path1 = os.path.join(save_path1, model_filename)\n",
    "\n",
    "    \n",
    "    # 加载模型\n",
    "    smart_model_v3 = SAC.load(model_path1)\n",
    "    # 计算平均最后时刻的累计收益\n",
    "    temp_self_reward,_,temp_oppo_reward,_= get_reward_episode(smart_model_v3, smart_env_v3, T, n_episodes)\n",
    "    \n",
    "    # 记录结果\n",
    "    self_rewards_v3.append(temp_self_reward[T-1])\n",
    "    oppo_rewards_v3.append(temp_oppo_reward[T-1])\n",
    "    timesteps.append(step)\n",
    "\n",
    "# 定义要保存的数据\n",
    "data = {\n",
    "    'self_rewards_v3': self_rewards_v3,\n",
    "    'oppo_rewards_v3': oppo_rewards_v3\n",
    "}\n",
    "# 保存数据到本地文件\n",
    "with open('/Users/fengyilong/Git/MAB_SAC/UCB_smart_v3/data_v3.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "print(\"数据已保存到 /Users/fengyilong/Git/MAB_SAC/UCB_smart_v3/data_v3.pkl\")\n",
    "\n",
    "# 绘制确定策略平均累计收益随训练次数的变化\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(timesteps, self_rewards_v3, label='Self Rewards v3')\n",
    "plt.plot(timesteps, oppo_rewards_v3, label='Opponent Rewards v3')\n",
    "plt.xlabel('Training Timesteps')\n",
    "plt.ylabel('Average Cumulative Reward v3')\n",
    "plt.title('Average Cumulative Reward vs Training Timesteps v3')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练的最终模型\n",
    "n_episodes = 50000\n",
    "smart_model_name_v3 = SAC.load(\"smart_UCB_v3\")\n",
    "\n",
    "# 调用 get_reward_episode 函数,计算确定策略和随机策略的每步的平均累计收益\n",
    "self_rewards_mean_v3, self_alphas_mean_v3, oppo_rewards_mean_v3, oppo_alphas_mean_v3 = get_reward_episode(smart_model_name_v3, smart_env_v3, T, n_episodes,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义要保存的数据\n",
    "data = {\n",
    "    'self_rewards_mean_v3': self_rewards_mean_v3,\n",
    "    'self_alphas_mean_v3': self_alphas_mean_v3,\n",
    "    'oppo_alphas_mean_v3': oppo_alphas_mean_v3,\n",
    "    'oppo_rewards_mean_v3': oppo_rewards_mean_v3\n",
    "}\n",
    "\n",
    "\n",
    "# 保存数据到本地文件\n",
    "with open('/Users/fengyilong/Git/MAB_SAC/UCB_smart_v3/data_inter_v3.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "print(\"数据已保存到 /Users/fengyilong/Git/MAB_SAC/UCB_smart_v3/data_inter_v3.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从本地文件加载数据\n",
    "with open('/Users/fengyilong/Git/MAB_SAC/UCB_smart_v3/data_inter_v3.pkl', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "# 访问加载的数据\n",
    "self_rewards_mean_v3 = loaded_data['self_rewards_mean_v3']\n",
    "self_alphas_mean_v3 = loaded_data['self_alphas_mean_v3']\n",
    "oppo_rewards_mean_v3 = loaded_data['oppo_rewards_mean_v3']\n",
    "oppo_alphas_mean_v3 = loaded_data['oppo_alphas_mean_v3']\n",
    "\n",
    "\n",
    "print(\"数据已从 /Users/fengyilong/Git/MAB_SAC/data_inter.pkl 加载\")\n",
    "\n",
    "\n",
    "# 绘制两种确定策略的每步的平均累计收益\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(self_rewards_mean_v3, label='Self Rewards v3')\n",
    "plt.plot(oppo_rewards_mean_v3, label='Oppoent Rewards v3')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Average Cumulative Reward v3')\n",
    "plt.title('Average Cumulative Reward vs Time Steps v3')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 绘制两种确定策略每步的平均alpha\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(self_alphas_mean_v3, label='Self Alpha v3')\n",
    "plt.plot(oppo_alphas_mean_v3, label='Opponent Alpha v3')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Average Alpha')\n",
    "plt.title('Average Alpha vs Time Steps v3')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
